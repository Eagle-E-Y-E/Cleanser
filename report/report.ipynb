{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Team 12\n",
    "$$ Report $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Interface\n",
    "![main interface](main.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement 1: Add additive noise to the image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Gaussian Noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise(image, mean=0, sigma=25):\n",
    "    sigma = sigma * 2.55  # Convert to [0, 255] range\n",
    "    noisy = image + np.random.normal(mean, sigma, image.shape) # guassian = normal distribution\n",
    "    return np.clip(noisy, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Salt & Pepper Noise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_salt_pepper_noise(image, salt_prob=0.02, pepper_prob=0.02):\n",
    "    noisy = np.copy(image)\n",
    "    total_pixels = image.size\n",
    "    num_salt = int(total_pixels * salt_prob)\n",
    "    num_pepper = int(total_pixels * pepper_prob)\n",
    "\n",
    "    # Add salt (white) noise\n",
    "    salt_coords = [np.random.randint(0, i, num_salt) for i in image.shape]\n",
    "    noisy[salt_coords[0], salt_coords[1]] = 255\n",
    "\n",
    "    # Add pepper (black) noise\n",
    "    pepper_coords = [np.random.randint(0, i, num_pepper) for i in image.shape]\n",
    "    noisy[pepper_coords[0], pepper_coords[1]] = 0\n",
    "\n",
    "    return noisy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Uniform Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_uniform_noise(image, intensity=50):\n",
    "    intensity = intensity * 2.55  # Convert to [0, 255] range\n",
    "    noisy = image + np.random.uniform(-intensity, intensity, image.shape)\n",
    "    return np.clip(noisy, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### screen shots\n",
    "<img src=\"salt&pepper.png\" width=\"40%\" align=\"left\"/>\n",
    "<img src=\"gaussian.png\" width=\"50%\" align=\"right\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement 2: Filters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Average Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_average_filter(image, kernel_size=30):\n",
    "    kernel = np.ones((kernel_size, kernel_size)) / (kernel_size ** 2)\n",
    "    # pad image to ensure that filter is applied to edges\n",
    "    padded_image = np.pad(image, ((kernel_size//2, kernel_size//2), (kernel_size //\n",
    "                          2, kernel_size//2), (0, 0)), mode='constant', constant_values=0)\n",
    "    filtered_image = np.zeros_like(image)\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            for k in range(image.shape[2]):\n",
    "                window = padded_image[i:i+kernel_size, j:j+kernel_size, k]\n",
    "                filtered_image[i, j, k] = np.sum(window * kernel)\n",
    "\n",
    "    return np.clip(filtered_image, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![average filter](avg_filter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Median Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_median_filter(image, kernel_size=3):\n",
    "    padded_image = np.pad(image, ((kernel_size//2, kernel_size//2), (kernel_size //\n",
    "                          2, kernel_size//2), (0, 0)), mode='constant', constant_values=0)\n",
    "    filtered_image = np.zeros_like(image)\n",
    "\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            for k in range(image.shape[2]):\n",
    "                region = padded_image[i:i+kernel_size, j:j+kernel_size, k]\n",
    "                filtered_image[i, j, k] = np.median(region)\n",
    "\n",
    "    return filtered_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![median filter](med_filter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Gaussian Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gaussian_filter(image, kernel_size=3, sigma=1):\n",
    "\n",
    "    ax = np.linspace(-(kernel_size // 2), kernel_size // 2,\n",
    "                     kernel_size)  # Generate a Gaussian kernel\n",
    "    gauss = np.exp(-0.5 * np.square(ax) / np.square(sigma))\n",
    "    kernel = np.outer(gauss, gauss)\n",
    "    kernel /= np.sum(kernel)\n",
    "\n",
    "    # Apply convolution\n",
    "    padded_image = np.pad(image, ((kernel_size//2, kernel_size//2), (kernel_size //\n",
    "                          2, kernel_size//2), (0, 0)), mode='constant', constant_values=0)\n",
    "    filtered_image = np.zeros_like(image)\n",
    "\n",
    "    for i in range(image.shape[0]):\n",
    "        for j in range(image.shape[1]):\n",
    "            for k in range(image.shape[2]):\n",
    "                region = padded_image[i:i+kernel_size, j:j+kernel_size, k]\n",
    "                filtered_image[i, j, k] = np.sum(region * kernel)\n",
    "\n",
    "    return np.clip(filtered_image, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gaussian_filter](gaussian_filter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement 3: Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Sobel filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sobel_kernel(self):\n",
    "    self.sobel_x = np.array([[-1, 0, 1],\n",
    "                                [-2, 0, 2],\n",
    "                                [-1, 0, 1]])\n",
    "\n",
    "    self.sobel_y = np.array([[-1, -2, -1],\n",
    "                                [0, 0, 0],\n",
    "                                [1, 2, 1]])\n",
    "    output_sobel_x = self.apply_kernel(self.sobel_x)\n",
    "    output_sobel_y = self.apply_kernel(self.sobel_y)\n",
    "    return output_sobel_x, output_sobel_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. Prewitt filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prewitt_kernel(self):\n",
    "    self.prewitt_x = np.array([[-1, 0, 1],\n",
    "                                [-1, 0, 1],\n",
    "                                [-1, 0, 1]])\n",
    "\n",
    "    self.prewitt_y = np.array([[-1, -1, -1],\n",
    "                                [0, 0, 0],\n",
    "                                [1, 1, 1]])\n",
    "    output_prewitt_x = self.apply_kernel(self.prewitt_x)\n",
    "    output_prewitt_y = self.apply_kernel(self.prewitt_y)\n",
    "    return output_prewitt_x, output_prewitt_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![prewitt_filter](prewitt_filter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3. Roberts filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roberts_kernel(self):\n",
    "    self.roberts_x = np.array([[1, 0],\n",
    "                                [0, -1]])\n",
    "\n",
    "    self.roberts_y = np.array([[0, 1],\n",
    "                                [-1, 0]])\n",
    "\n",
    "    output_roberts_x = self.apply_kernel(self.roberts_x)\n",
    "    output_roberts_y = self.apply_kernel(self.roberts_y)\n",
    "    return output_roberts_x, output_roberts_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![rob_filter](rob_filter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4. Canny filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_kernel(self, image):\n",
    "    #Apply Gaussian blur\n",
    "    # Compute gradients using Sobel filters.\n",
    "    # Apply Non-Maximum Suppression.\n",
    "    # Implement Double Thresholding.\n",
    "    # Apply Edge Tracking by Hysteresis.\n",
    "    blurred = cv2.GaussianBlur(image, (5, 5), 1.4)\n",
    "    output_image = cv2.Canny(blurred, 20, 200)\n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![canny_filter](canny_filter.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Output Calculation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_edges(self):\n",
    "    self.edge_detector.mask_selection = self.main_window.edge_detection_method_combo.currentText()\n",
    "    self.edge_detector.image = self.gray_image\n",
    "    gradient_magnitude = [[]]\n",
    "\n",
    "    if self.edge_detector.mask_selection == \"Sobel\":\n",
    "        Gx, Gy = self.edge_detector.sobel_kernel()\n",
    "        gradient_magnitude = np.sqrt(Gx ** 2 + Gy ** 2)\n",
    "\n",
    "    elif self.edge_detector.mask_selection == \"Prewitt\":\n",
    "        Gx, Gy = self.edge_detector.prewitt_kernel()\n",
    "        gradient_magnitude = np.sqrt(Gx ** 2 + Gy ** 2)\n",
    "\n",
    "    elif self.edge_detector.mask_selection == \"Roberts\":\n",
    "        Gx, Gy = self.edge_detector.roberts_kernel()\n",
    "        gradient_magnitude = np.sqrt(Gx ** 2 + Gy ** 2)\n",
    "\n",
    "    elif self.edge_detector.mask_selection == \"Canny\":\n",
    "        gradient_magnitude = self.edge_detector.canny_kernel(\n",
    "            self.edge_detector.image)\n",
    "\n",
    "    \n",
    "    gradient_magnitude = (gradient_magnitude / gradient_magnitude.max()) * 255\n",
    "    gradient_magnitude = gradient_magnitude.astype(np.uint8)\n",
    "    self.output_image = gradient_magnitude\n",
    "    self.display_image(self.output_image_view, gradient_magnitude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement 4: Draw Histogram & CDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1. Histogram (clear details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_histogram(image):\n",
    "    histogram = np.zeros(256, dtype=int)\n",
    "    for pixel_value in image.flatten():\n",
    "        histogram[pixel_value] += 1\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2. CDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_CDF(histogram, grey_levels=256):\n",
    "    cdf = np.cumsum(histogram)\n",
    "    cdf_norm = np.round(cdf / cdf[-1] * (grey_levels - 1)).astype(int)\n",
    "    return cdf_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"histogram.png\" width=\"50%\" align=\"left\"/>\n",
    "<img src=\"cdf.png\" width=\"50%\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement 5: Image Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equalize(image, grey_levels=256):\n",
    "    if image is None: return\n",
    "    image_shape = image.shape\n",
    "    histogram = HistogramEqualization.compute_histogram(image)\n",
    "    cdf_norm = HistogramEqualization.compute_CDF(histogram, grey_levels)\n",
    "    equalized_hist = np.zeros(grey_levels, dtype=int)\n",
    "    for i in range(grey_levels):\n",
    "        equalized_hist[cdf_norm[i]] += histogram[i]\n",
    "    new_flattened_image = cdf_norm[image]\n",
    "    new_image = new_flattened_image.reshape(image_shape)\n",
    "    return histogram, equalized_hist, new_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![hist](hist.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement 6: Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image):\n",
    "    # Convert the image to a numpy array if it's not already\n",
    "    image = np.array(image)\n",
    "    \n",
    "    # Get the minimum and maximum values from the image\n",
    "    min_val = np.min(image)\n",
    "    max_val = np.max(image)\n",
    "    \n",
    "    # Normalize the image using vectorized operations\n",
    "    normalized = ((image - min_val) / (max_val - min_val)) * 255\n",
    "    \n",
    "    # Return the normalized image\n",
    "    return normalized.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement 7: Thresholding\n",
    "1. Global\n",
    "    * Parameters used: Threshold value\n",
    "\n",
    "    ![th](global_th.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_thresholding(image, threshold):\n",
    "    # Apply thresholding using NumPy vectorization\n",
    "    thresholded_image = (image > threshold) * 255\n",
    "    # ensures the image has the correct data type for saving and displaying\n",
    "    thresholded_image = thresholded_image.astype('uint8')\n",
    "    return thresholded_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![t](t1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Local\n",
    "\n",
    "    * Type used: Local mean thresholding\n",
    "    * Parameters used: window size & Sensitivity(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_thresholding(image, window_size, C):\n",
    "    # Ensure window size is odd\n",
    "    # if window_size % 2 == 0:\n",
    "    #     raise ValueError(\"window_size must be an odd integer.\")\n",
    "\n",
    "    # Pad the image to handle borders\n",
    "    pad_size = window_size // 2\n",
    "    padded_image = np.pad(image, pad_size, mode='reflect')\n",
    "\n",
    "    # Create an empty array for the thresholded image\n",
    "    thresholded_image = np.zeros_like(image, dtype=np.uint8)\n",
    "\n",
    "    # Iterate over each pixel in the original image\n",
    "    for y in range(image.shape[0]):\n",
    "        for x in range(image.shape[1]):\n",
    "            # Extract the local window\n",
    "            y0, y1 = y, y + window_size\n",
    "            x0, x1 = x, x + window_size\n",
    "            window = padded_image[y0:y1, x0:x1]\n",
    "\n",
    "            # Calculate the local mean\n",
    "            local_mean = np.mean(window)\n",
    "\n",
    "            # Calculate local threshold and apply it\n",
    "            T_local = local_mean - C\n",
    "            thresholded_image[y, x] = 255 if image[y, x] > T_local else 0\n",
    "\n",
    "    return thresholded_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![th1](local_th.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement 8: Converting from RGB to Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_grayscale(image):\n",
    "    # Ensure the image has three channels (BGR)\n",
    "    if len(image.shape) != 3 or image.shape[2] != 3:\n",
    "        raise ValueError(\"Input image must be a BGR image with 3 channels.\")\n",
    "\n",
    "    # Get image dimensions\n",
    "    height, width, channels = image.shape\n",
    "\n",
    "    # Initialize a new array for the grayscale image\n",
    "    grayscale_image = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "    # Convert to grayscale using the luminance formula\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            # Get BGR values (OpenCV uses BGR format)\n",
    "            B, G, R = image[y, x]\n",
    "\n",
    "            # Calculate grayscale value\n",
    "            gray = int(0.299 * R + 0.587 * G + 0.114 * B)\n",
    "\n",
    "            # Assign the grayscale value to the new image\n",
    "            grayscale_image[y, x] = gray\n",
    "\n",
    "    return grayscale_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![grayscale](grayscale.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* RGB Histogram\n",
    "    * By extracting the R, G and B values from the image, We plot each channelâ€™s histogram individually\n",
    "\n",
    "    * Computed Histogram: By counting the frequencies of each intensity value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_histogram(channel_values):\n",
    "    # Initialize histogram with zeros for all possible intensity values (0-255)\n",
    "    histogram = [0] * 256\n",
    "\n",
    "    # Count the frequency of each intensity value\n",
    "    for value in channel_values:\n",
    "        histogram[value] += 1\n",
    "\n",
    "    return histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Compute CDF: By getting the probabilities of each intensity and sum them till it reaches 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cdf(histogram):\n",
    "    cdf = []\n",
    "    cumulative = 0\n",
    "    total_pixels = sum(histogram)\n",
    "    for count in histogram:\n",
    "        cumulative += count\n",
    "        cdf_value = cumulative / total_pixels  # Normalize to [0,1]\n",
    "        cdf.append(cdf_value)\n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement 9: Frequency Filters\n",
    "* Parameters used: Cut Off Frequency\n",
    "* Steps:\n",
    "1. Getting fourier transform\n",
    "2. Creating filter by computing Euclidean distance and whether the filter is low or high, the intensity value is changed according to the cut off frequency and the filter type\n",
    "\tEuclidean distance equation: \n",
    "    \n",
    "    ![11](8.png)\n",
    "3. Applying filter by element wise multiplication\n",
    "4. Getting inverse fourier transform\n",
    "5. Normalizing the image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirement 10: Hybrid Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* By taking low frequencies from one image and high frequencies from the other image and adding both we can get the hybrid image\n",
    "Gaussian Kernel is generated by **gaussian function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_gaussian_kernel(size, sigma):\n",
    "    ax = np.arange(-size // 2 + 1., size // 2 + 1.)\n",
    "    xx, yy = np.meshgrid(ax, ax)\n",
    "    kernel = np.exp(-(xx**2 + yy**2) / (2. * sigma**2))\n",
    "    kernel = kernel / np.sum(kernel)\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Parameters used: Kernel size & Sigma\n",
    "![hyprid](hyprid.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
